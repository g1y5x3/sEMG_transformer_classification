{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import normalize, onehot, count_parameters\n",
    "from model import TransformerModel\n",
    "from sEMGdata import sEMGData, sEMGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "  print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of subjects:       40\n",
      "Testing Subject ID:             44\n",
      "Testing Subject VFI-1:          0\n",
      "# of Testing Samples:           165\n",
      "# of Healthy Training Samples:  3037\n",
      "# of Fatigued Training Samples: 3270\n"
     ]
    }
   ],
   "source": [
    "# load the data and labels\n",
    "sEMG_vowels = sEMGData(file_dir=\"data/subjects_40_vowels_v6.mat\")\n",
    "\n",
    "# leave-one-subject-out data partition\n",
    "x_train, y_train, x_test, y_test = sEMG_vowels.load_data(sub_test=0, sub_normalize=True)\n",
    "# Normalize the signal per channel\n",
    "x_train, x_test = normalize(x_train, x_test)\n",
    "# Onehot encode the label\n",
    "y_train, y_test = onehot(y_train), onehot(y_test)\n",
    "# TODO: split into training and validation\n",
    "\n",
    "train_dataset = sEMGDataset(x_train, y_train, dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Parameters: 818306\n",
      "torch.Size([32, 4000, 4]) torch.float16\n",
      "torch.Size([32, 2]) torch.float16\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n",
    "model = TransformerModel(feat_dim=4, d_model=64, n_head=8, d_hid=256, n_layer=1)\n",
    "batcher = iter(train_loader)\n",
    "model.half().to(device)\n",
    "print(f\"Total Model Parameters: {count_parameters(model)}\")\n",
    "\n",
    "x,y = next(batcher)\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2]) torch.float16\n"
     ]
    }
   ],
   "source": [
    "x, y = x.to(device), y.to(device)\n",
    "y_pred = model(x)\n",
    "print(y_pred.shape, y_pred.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n",
      "Memory Usage:\n",
      "Allocated: 0.4 GB\n",
      "Cached:    0.4 GB\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print('Memory Usage:')\n",
    "  print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "  print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i = np.random.randint(x_train.shape[0])\n",
    "plt.plot(x_train[i,:,0])\n",
    "plt.xlim([0, 4000])\n",
    "plt.ylim([-5,5])\n",
    "if y_train[i,0] == 1:\n",
    "  plt.title(\"Healthy Sample\")\n",
    "else:\n",
    "  plt.title(\"Fatigued Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
